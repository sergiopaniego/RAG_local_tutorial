{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/sergiopaniego/RAG_local_tutorial/blob/main/example_rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG example with Langchain, Ollama and and open-source LLM model\n",
    "\n",
    "In this example, we first connect to an LLM locally and make request to the LLM that Ollama is serving using LangChain. After that, we generate our RAG application from a PDF file and extract details from that document.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/langchain3.png\" alt=\"Langchain Logo\" width=\"20%\">\n",
    "  <img src=\"https://bookface-images.s3.amazonaws.com/logos/ee60f430e8cb6ae769306860a9c03b2672e0eaf2.png\" alt=\"Ollama Logo\" width=\"20%\">\n",
    "</p>\n",
    "\n",
    "Sources:\n",
    "\n",
    "* https://github.com/svpino/llm\n",
    "* https://github.com/AIAnytime/Gemma-7B-RAG-using-Ollama/blob/main/Ollama%20Gemma.ipynb\n",
    "* https://www.youtube.com/watch?v=-MexTC18h20&ab_channel=AIAnytime\n",
    "* https://www.youtube.com/watch?v=HRvyei7vFSM&ab_channel=Underfitted\n",
    "\n",
    " \n",
    "# Requirements\n",
    "\n",
    "* Ollama installed locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the requirements\n",
    "\n",
    "If an error is raised related to docarray, refer to this solution: https://stackoverflow.com/questions/76880224/error-using-using-docarrayinmemorysearch-in-langchain-could-not-import-docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain\n",
    "!pip3 install langchain_pinecone\n",
    "!pip3 install langchain[docarray]\n",
    "!pip3 install docarray\n",
    "!pip3 install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the LLM model to use\n",
    "\n",
    "The model must be downloaded locally to be used, so if you want to run llama3, you should run:\n",
    "\n",
    "```\n",
    "\n",
    "ollama pull llama3\n",
    "\n",
    "```\n",
    "\n",
    "Check the list of models available for Ollama here: https://ollama.com/library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"mixtral:8x7b\"\n",
    "#MODEL = \"gemma:7b\"\n",
    "#MODEL = \"llama2\"\n",
    "MODEL = \"llama3\" # https://ollama.com/library/llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We instanciate the LLM model and the Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiopaniegoblanco/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here\\'s one:\\n\\n\"The greatest glory in living lies not in never falling, but in rising every time we fall.\" - Nelson Mandela\\n\\nI hope it inspires you to get back up and keep moving forward, no matter what challenges you may face!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n",
    "model.invoke(\"Give me an inspirational quote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 2+2 is... 4!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Waht is 2+2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a parser provided by LangChain, we can transform the LLM output to something more suitable to be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "\"Believe you can and you're halfway there.\" - Theodore Roosevelt\n",
      "\n",
      "I hope that inspires you to tackle your goals and pursue your dreams with confidence!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "response_from_model = model.invoke(\"Give me an inspirational quote\")\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We generate the template for the conversation with the instruct-based LLM\n",
    "\n",
    "We can create a template to structure the conversation effectively.\n",
    "\n",
    "This template allows us to provide some general context to the Language Learning Model (LLM), which will be utilized for every prompt. This ensures that the model has a consistent background understanding for all interactions.\n",
    "\n",
    "Additionally, we can include specific context relevant to the particular prompt. This helps the model understand the immediate scenario or topic before addressing the actual question. Following this specific context, we then present the actual question we want the model to answer.\n",
    "\n",
    "By using this approach, we enhance the model's ability to generate accurate and relevant responses based on both the general and specific contexts provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, answer with \"I don\\'t know\".\\n\\nContext: Here is some context\\n\\nQuestion: Here is a question\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can answer prompts based on the context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Sergio!\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What's your name?\")\n",
    "response_from_model = model.invoke(formatted_prompt)\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can't answer what is not provided as context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know! The provided context only tells me that your parents named you Sergio, but it doesn't mention anything about your age. I can't infer or guess your age based on this information.\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What's my age?\")\n",
    "response_from_model = model.invoke(formatted_prompt)\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even previously known info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know!\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What is 2+2?\")\n",
    "response_from_model = model.invoke(formatted_prompt)\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an example PDF to do Retrieval Augmented Generation (RAG)\n",
    "\n",
    "For the example, you can select your own PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nCurr ently teaching assistant for:\\nSubject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n\\x00Couses:\\nCourse name Wher e When\\nIntroduction t o Coding ISDI (DMBA, MBA)December\\n2023 -\\nIntroduction t o Arti\\x00cial Intelligence IES E uropa, MadridNovember\\n2023\\nIntroduction t o Programming with P ython Atenea F ormaci贸nNovember\\n2023\\nIntroduction t o Arti\\x00cial Intelligence and\\nits A pplicationsAtenea F ormaci贸n July 2023\\nObject detection and segmentation with\\nTensor\\x00owPlatzi July 2022\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 1/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
       " Document(page_content='Selected talks:\\nTalk name Wher e When\\nWhat happens when we combine video\\ngames with ChatGPT? Giving lif e to NPCsUbuP arty, Bur gosSeptember\\n2023\\nVision based end-t o-end aut onomous\\ndriving via imitation learningMaster in Ar ti\\x00cial Vision, URJC, MadridMarch\\n2023\\nRL-Studio: A Tool for Reinfor cement\\nLearning Methods in RoboticsROBO T 2022 Conf erence, Zar agozaNovember\\n2022\\nMaster thesis dir ected:\\nThesis name Student When\\nConducci贸n aut 贸noma en tr 谩\\x00co usando\\naprendizaje pr ofundo extr emo a extr emo\\n(Autonomous driving in tr a\\x00c using end-\\nto-end deep learning)Enrique Y . Shinohar a Sot oMaster\\nin\\nArti\\x00cial\\nVision,\\nURJC,\\n2022-\\n2023\\nReviewer:\\nJournal/Conf erence When\\n(Journal) Exper t Systems 2023\\n(Conf erence) W orkshop on Physical Agents ( WAF) 2023\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 2/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 1}),\n",
       " Document(page_content='Previous teaching experience:\\nSubject Wher e When\\nModelling and Simulation of Robots3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\nEmbedded and Real Time Systems3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 3/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(\"./files/teaching.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "#pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nCurr ently teaching assistant for:\\nSubject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n\\x00Couses:\\nCourse name Wher e When\\nIntroduction t o Coding ISDI (DMBA, MBA)December\\n2023 -\\nIntroduction t o Arti\\x00cial Intelligence IES E uropa, MadridNovember\\n2023\\nIntroduction t o Programming with P ython Atenea F ormaci贸nNovember\\n2023\\nIntroduction t o Arti\\x00cial Intelligence and\\nits A pplicationsAtenea F ormaci贸n July 2023\\nObject detection and segmentation with\\nTensor\\x00owPlatzi July 2022\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 1/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
       " Document(page_content='Selected talks:\\nTalk name Wher e When\\nWhat happens when we combine video\\ngames with ChatGPT? Giving lif e to NPCsUbuP arty, Bur gosSeptember\\n2023\\nVision based end-t o-end aut onomous\\ndriving via imitation learningMaster in Ar ti\\x00cial Vision, URJC, MadridMarch\\n2023\\nRL-Studio: A Tool for Reinfor cement\\nLearning Methods in RoboticsROBO T 2022 Conf erence, Zar agozaNovember\\n2022\\nMaster thesis dir ected:\\nThesis name Student When\\nConducci贸n aut 贸noma en tr 谩\\x00co usando\\naprendizaje pr ofundo extr emo a extr emo\\n(Autonomous driving in tr a\\x00c using end-\\nto-end deep learning)Enrique Y . Shinohar a Sot oMaster\\nin\\nArti\\x00cial\\nVision,\\nURJC,\\n2022-\\n2023\\nReviewer:\\nJournal/Conf erence When\\n(Journal) Exper t Systems 2023\\n(Conf erence) W orkshop on Physical Agents ( WAF) 2023\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 2/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 1}),\n",
       " Document(page_content='Previous teaching experience:\\nSubject Wher e When\\nModelling and Simulation of Robots3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\nEmbedded and Real Time Systems3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\n漏 Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 3/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text_documents = text_splitter.split_documents(pages)[:5]\n",
    "\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the PDF in a vector space.\n",
    "\n",
    "From Langchain docs:\n",
    "\n",
    "`DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.`\n",
    "\n",
    "The execution time of the following block depends on the complexity and longitude of the PDF provided. Try to keep it small and simple for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create retriever of vectors that are similar to be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Introduction t o Coding ISDI (DMBA, MBA)December\\n2023 -', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
       " Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nCurr ently teaching assistant for:', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
       " Document(page_content='Univ ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
       " Document(page_content='Subject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate conversate with the document to extract the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming retriever is an instance of a retriever class and has a method to retrieve context\n",
    "retrieved_context = retriever.invoke(\"artificial intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are his research interests?\n",
      "Answer: I don't know. The provided context does not mention the specific research interests of Sergio Paniego, but it does show the courses and topics he is teaching or has taught in the past. If you're looking for information on his research interests, I recommend searching for academic articles, presentations, or online profiles where he may have shared his research areas of focus.\n",
      "\n",
      "Question: Does he have teaching experience?\n",
      "Answer: Based on the context, it appears that the individual has teaching experience. The documents mention \"teaching talks\" and \"teaching assistant\", which suggests that they have experience in this area. Therefore, my answer is:\n",
      "\n",
      "Yes, he has teaching experience.\n",
      "\n",
      "Question: Does he know about Tensorflow?\n",
      "Answer: I don't know. The provided context only shows documents related to teaching talks and course information, but it does not mention TensorFlow specifically. Therefore, I cannot determine whether the person knows about TensorFlow based on this information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What are his research interests?\",\n",
    "    \"Does he have teaching experience?\",\n",
    "    \"Does he know about Tensorflow?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
    "    response_from_model = model.invoke(formatted_prompt)\n",
    "    parsed_response = parser.parse(response_from_model)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {parsed_response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop to ask-answer questions continously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"Say 'exit' or 'quit' to exit the loop\")\n",
    "    question = input('User question: ')\n",
    "    print(f\"Question: {question}\")\n",
    "    if question.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting the conversation. Goodbye!\")\n",
    "        break\n",
    "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
    "    response_from_model = model.invoke(formatted_prompt)\n",
    "    parsed_response = parser.parse(response_from_model)\n",
    "    print(f\"Answer: {parsed_response}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
